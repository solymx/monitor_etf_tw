import requests
import pandas as pd
from datetime import datetime
import os
import glob
import shutil
import traceback

# --- è¨­å®šå€ ---
API_URL = "https://www.capitalfund.com.tw/CFWeb/api/etf/buyback"
FUND_ID = "399"   # âš ï¸ è«‹ç¢ºèªé€™æ˜¯ä½ è¦æŠ“çš„åŸºé‡‘ä»£è™Ÿ (399=00929)ã€‚å¦‚æœè¦æŠ“ 00982ï¼Œè«‹å¡«å…¥æ­£ç¢ºä»£è™Ÿã€‚
FILE_TAG = "00982a"  # æª”åè­˜åˆ¥å­— (ç”Ÿæˆçš„æª”æ¡ˆæœƒæ˜¯ YYYYMMDD_00982a.csv)
BACKUP_FOLDER = "982a" # å‚™ä»½èˆŠæª”æ¡ˆçš„è³‡æ–™å¤¾åç¨±

# Payload
payload = {
    "fundId": FUND_ID,
    "date": None 
}

# Headers
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Content-Type": "application/json",
    "Referer": "https://www.capitalfund.com.tw/"
}

def get_previous_csv():
    """
    å°‹æ‰¾ç•¶å‰ç›®éŒ„ä¸‹æœ€è¿‘çš„ä¸€ä»½èˆŠ CSV æª”æ¡ˆ
    """
    # æ‰¾å°‹æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„ CSV
    csv_files = glob.glob(f"*_{FILE_TAG}.csv")
    
    # å¦‚æœæ²’æœ‰ä»»ä½•æª”æ¡ˆï¼Œå›å‚³ None
    if not csv_files:
        return None
    
    # æ ¹æ“šæª”åæ’åº (æ—¥æœŸåœ¨å‰é¢ï¼Œæ‰€ä»¥æ’åºæœ€å¾Œä¸€å€‹å°±æ˜¯æœ€è¿‘æ—¥æœŸçš„)
    csv_files.sort()
    
    # å–å‡ºæœ€å¾Œä¸€å€‹æª”æ¡ˆ
    latest_file = csv_files[-1]
    
    print(f"ğŸ” æ‰¾åˆ°ä¸Šä¸€ä»½è³‡æ–™é€²è¡Œæ¯”å°: {latest_file}")
    return latest_file

def analyze_changes(today_df, prev_file_path):
    """
    æ¯”å°ä»Šæ—¥èˆ‡æ˜¨æ—¥æŒè‚¡ï¼Œç”¢ç”Ÿç‹€æ…‹æ¬„ä½
    """
    if not prev_file_path:
        # å¦‚æœæ²’æœ‰èˆŠæª”æ¡ˆï¼Œæ‰€æœ‰è‚¡ç¥¨éƒ½ç®— "æ–°è³‡æ–™"
        today_df['ç‹€æ…‹'] = 'ğŸ†• é¦–æ¬¡æŠ“å–'
        today_df['è‚¡æ•¸è®ŠåŒ–'] = 0
        return today_df

    # è®€å–èˆŠæª”æ¡ˆ
    try:
        # ğŸŸ¢ã€ä¿®æ­£é» 1ã€‘è®€å–æ™‚æŒ‡å®š 'è‚¡ç¥¨ä»£è™Ÿ' ç‚ºå­—ä¸²ï¼Œé¿å… 0050 è®Šæˆ 50
        prev_df = pd.read_csv(prev_file_path, dtype={'è‚¡ç¥¨ä»£è™Ÿ': str})
        
        # é›™é‡ä¿éšªï¼šç¢ºä¿è½‰ç‚ºå­—ä¸²ä¸¦å»é™¤ç©ºç™½
        prev_df['è‚¡ç¥¨ä»£è™Ÿ'] = prev_df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.strip()

        # åªå–éœ€è¦çš„æ¬„ä½ä¾†æ¯”å°
        prev_df = prev_df[['è‚¡ç¥¨ä»£è™Ÿ', 'æŒæœ‰è‚¡æ•¸', 'è‚¡ç¥¨åç¨±']]
        prev_df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'æ˜¨æ—¥è‚¡æ•¸', 'æ˜¨æ—¥åç¨±'] # æ”¹åé¿å…è¡çª
    except Exception as e:
        print(f"âš ï¸ è®€å–èˆŠæª”æ¡ˆå¤±æ•— ({e})ï¼Œç•¥éæ¯”å°")
        today_df['ç‹€æ…‹'] = '-'
        return today_df

    # --- é—œéµæ­¥é©Ÿï¼šåˆä½µ (Outer Join) ä»¥åŒ…å«è³£å‡ºçš„è‚¡ç¥¨ ---
    # ğŸŸ¢ ç¾åœ¨å…©é‚Šçš„ 'è‚¡ç¥¨ä»£è™Ÿ' éƒ½æ˜¯å­—ä¸² (Object)ï¼Œå¯ä»¥å®‰å…¨åˆä½µäº†
    merged_df = pd.merge(today_df, prev_df, on='è‚¡ç¥¨ä»£è™Ÿ', how='outer')

    # å¡«è£œåç¨±ï¼šå¦‚æœæ˜¯ã€Œè³£å‡ºã€çš„è‚¡ç¥¨ï¼Œtoday_df çš„è‚¡ç¥¨åç¨±æœƒæ˜¯ NaNï¼Œè¦ç”¨èˆŠæª”æ¡ˆçš„åç¨±è£œå›ä¾†
    merged_df['è‚¡ç¥¨åç¨±'] = merged_df['è‚¡ç¥¨åç¨±'].fillna(merged_df['æ˜¨æ—¥åç¨±'])

    # è¨ˆç®—è®ŠåŒ–
    merged_df['æŒæœ‰è‚¡æ•¸'] = merged_df['æŒæœ‰è‚¡æ•¸'].fillna(0) # ä»Šå¤©æ²’è‚¡æ•¸ = 0
    merged_df['æ˜¨æ—¥è‚¡æ•¸'] = merged_df['æ˜¨æ—¥è‚¡æ•¸'].fillna(0) # æ˜¨å¤©æ²’è‚¡æ•¸ = 0
    merged_df['è‚¡æ•¸è®ŠåŒ–'] = merged_df['æŒæœ‰è‚¡æ•¸'] - merged_df['æ˜¨æ—¥è‚¡æ•¸']

    # å®šç¾©ç‹€æ…‹åˆ¤æ–·å‡½å¼
    def determine_status(row):
        if row['æ˜¨æ—¥è‚¡æ•¸'] == 0 and row['æŒæœ‰è‚¡æ•¸'] > 0:
            return "ğŸ”¥ æ–°é€²"
        elif row['æŒæœ‰è‚¡æ•¸'] == 0 and row['æ˜¨æ—¥è‚¡æ•¸'] > 0:
            return "ğŸ‘‹ è³£å‡º"
        elif row['è‚¡æ•¸è®ŠåŒ–'] > 0:
            return "ğŸ”º å¢åŠ "
        elif row['è‚¡æ•¸è®ŠåŒ–'] < 0:
            return "ğŸ”» æ¸›å°‘"
        else:
            return "â– æŒå¹³"

    merged_df['ç‹€æ…‹'] = merged_df.apply(determine_status, axis=1)

    # æ•´ç†æ¬„ä½ (ç§»é™¤è¼”åŠ©ç”¨çš„æ¬„ä½)
    final_df = merged_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æ¬Šé‡(%)', 'æŒæœ‰è‚¡æ•¸', 'è‚¡æ•¸è®ŠåŒ–', 'ç‹€æ…‹']]
    
    # æ’åºï¼šæŒæœ‰çš„æ’ä¸Šé¢ (æ¬Šé‡é«˜åˆ°ä½)ï¼Œè³£å‡ºçš„æ’æœ€å¾Œ
    final_df = final_df.sort_values(by=['æ¬Šé‡(%)'], ascending=False, na_position='last')
    
    return final_df

def manage_backups(today_filename):
    """
    å°‡éä»Šæ—¥çš„èˆŠ CSV æª”æ¡ˆç§»å‹•åˆ°å‚™ä»½è³‡æ–™å¤¾
    """
    # ç¢ºä¿å‚™ä»½è³‡æ–™å¤¾å­˜åœ¨
    if not os.path.exists(BACKUP_FOLDER):
        os.makedirs(BACKUP_FOLDER)
        # print(f"ğŸ“ å»ºç«‹å‚™ä»½è³‡æ–™å¤¾: {BACKUP_FOLDER}")

    # æœå°‹æ ¹ç›®éŒ„ä¸‹çš„ç›®æ¨™ CSV
    files = glob.glob(f"*_{FILE_TAG}.csv")
    
    for file in files:
        # å¦‚æœé€™å€‹æª”æ¡ˆ "ä¸æ˜¯" ä»Šå¤©è¦ç”¢ç”Ÿçš„æª”æ¡ˆï¼Œå°±æ¬é€²å»
        if file != today_filename:
            destination = os.path.join(BACKUP_FOLDER, file)
            # å¦‚æœå‚™ä»½è³‡æ–™å¤¾å·²ç¶“æœ‰åŒåæª”æ¡ˆï¼Œå…ˆåˆªé™¤èˆŠçš„ä»¥é¿å…å ±éŒ¯
            if os.path.exists(destination):
                os.remove(destination)
            
            shutil.move(file, destination)
            print(f"ğŸ“¦ å·²å‚™ä»½èˆŠæª”æ¡ˆ: {file} -> {BACKUP_FOLDER}/")

def save_html(df, file_path, title_date):
    """
    å­˜æˆæ¼‚äº®çš„ HTMLï¼ŒåŠ å…¥é¡è‰²æ¨™ç¤º
    """
    # é‡å°ç‹€æ…‹åšé¡è‰²æ¨™è¨˜çš„å‡½å¼ (CSS)
    def color_status(val):
        color = 'black'
        weight = 'normal'
        if 'æ–°é€²' in val: color = 'red'; weight = 'bold'
        elif 'å¢åŠ ' in val: color = '#d9534f' # ç´…è‰²ç³»
        elif 'æ¸›å°‘' in val: color = 'green'
        elif 'è³£å‡º' in val: color = 'gray'; weight = 'bold'
        return f'color: {color}; font-weight: {weight}'

    # é‡å°æ•´åˆ—åšèƒŒæ™¯è‰²çš„å‡½å¼ (è³£å‡ºé¡¯ç¤ºç°è‰²èƒŒæ™¯)
    def row_style(row):
        if 'è³£å‡º' in row['ç‹€æ…‹']:
            return ['background-color: #f9f9f9; color: #999'] * len(row)
        return [''] * len(row)

    # ç”¢ç”Ÿ HTML è¡¨æ ¼
    try:
        styler = df.style.map(color_status, subset=['ç‹€æ…‹'])
    except AttributeError:
        styler = df.style.applymap(color_status, subset=['ç‹€æ…‹'])

    styler = styler.apply(row_style, axis=1)\
                   .format({'æ¬Šé‡(%)': "{:.2f}", 'æŒæœ‰è‚¡æ•¸': "{:,.0f}", 'è‚¡æ•¸è®ŠåŒ–': "{:+,.0f}"})
    
    html_content = styler.to_html()

    html_template = f"""
    <html>
    <head>
        <meta charset="utf-8">
        <title>ETF æŒè‚¡ç›£æ§ - {title_date}</title>
        <style>
            body {{ font-family: "Microsoft JhengHei", Arial, sans-serif; margin: 20px; background-color: #fdfdfd; }}
            h2 {{ color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
            table {{ border-collapse: collapse; width: 100%; max-width: 900px; margin-top: 15px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
            th {{ background-color: #007bff; color: white; padding: 12px; text-align: left; }}
            td {{ border-bottom: 1px solid #ddd; padding: 10px; }}
            tr:hover {{ background-color: #f1f1f1; }}
        </style>
    </head>
    <body>
        <h2>ğŸ“Š {FILE_TAG} æŒè‚¡è®ŠåŒ–æ—¥å ± ({title_date})</h2>
        {html_content}
        <p style="color: #666; font-size: 0.9em;">è³‡æ–™ç”¢ç”Ÿæ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
    </body>
    </html>
    """
    
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(html_template)

def main():
    print(f"ğŸš€ é–‹å§‹æŠ“å– ETF ä»£è™Ÿ {FUND_ID} çš„æŒè‚¡è³‡æ–™...")
    
    try:
        response = requests.post(API_URL, json=payload, headers=headers)
        
        if response.status_code == 200:
            raw_data = response.json()
            
            if 'data' in raw_data and 'stocks' in raw_data['data']:
                stock_list = raw_data['data']['stocks']
                
                if stock_list:
                    # 1. è½‰æˆ DataFrame
                    df = pd.DataFrame(stock_list)
                    
                    # 2. æ¸…æ´—è³‡æ–™
                    df = df[['stocNo', 'stocName', 'weight', 'shareFormat']]
                    df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æ¬Šé‡(%)', 'æŒæœ‰è‚¡æ•¸']
                    
                    # ğŸŸ¢ã€ä¿®æ­£é» 2ã€‘å¼·åˆ¶å°‡ä»Šæ—¥è³‡æ–™çš„è‚¡ç¥¨ä»£è™Ÿè½‰ç‚ºå­—ä¸²ï¼Œä¸¦å»é™¤ç©ºç™½
                    df['è‚¡ç¥¨ä»£è™Ÿ'] = df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.strip()
                    
                    # è½‰å‹æ…‹ç¢ºä¿è¨ˆç®—æ­£ç¢º (ç§»é™¤é€—è™Ÿè½‰æ•¸å­—)
                    df['æŒæœ‰è‚¡æ•¸'] = df['æŒæœ‰è‚¡æ•¸'].astype(str).str.replace(',', '').astype(float)
                    
                    # 3. å°‹æ‰¾èˆŠæª”æ¡ˆä¸¦é€²è¡Œæ¯”å°
                    prev_csv = get_previous_csv()
                    final_df = analyze_changes(df, prev_csv)
                    
                    # 4. æº–å‚™æª”å
                    today_str = datetime.now().strftime("%Y%m%d")
                    csv_filename = f"{today_str}_{FILE_TAG}.csv"
                    html_filename = f"{today_str}_{FILE_TAG}.html"
                    
                    # 5. æª”æ¡ˆç®¡ç† (å‚™ä»½èˆŠçš„ CSV)
                    manage_backups(csv_filename)
                    
                    # 6. å„²å­˜æœ€æ–°çš„ CSV èˆ‡ HTML åˆ°æ ¹ç›®éŒ„
                    final_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
                    save_html(final_df, html_filename, today_str)
                    
                    print(f"\nâœ… å®Œæˆï¼")
                    print(f"   - æœ€æ–° CSV: {csv_filename}")
                    print(f"   - æœ€æ–° HTML: {html_filename}")
                    print(f"   - æ­·å²å‚™ä»½: è©³è¦‹ {BACKUP_FOLDER}/ è³‡æ–™å¤¾")
                    
                    # é¡¯ç¤ºè®ŠåŒ–æ‘˜è¦ (åœ¨çµ‚ç«¯æ©Ÿé è¦½)
                    changes = final_df[final_df['ç‹€æ…‹'].isin(['ğŸ”¥ æ–°é€²', 'ğŸ‘‹ è³£å‡º', 'ğŸ”º å¢åŠ ', 'ğŸ”» æ¸›å°‘'])]
                    if not changes.empty:
                        print(f"\nğŸ“¢ ä»Šæ—¥ç•°å‹• ({len(changes)} ç­†):")
                        print(changes[['è‚¡ç¥¨åç¨±', 'ç‹€æ…‹', 'è‚¡æ•¸è®ŠåŒ–']].to_string(index=False))
                    else:
                        print("\nğŸ’¤ ä»Šæ—¥æŒè‚¡ç„¡è®ŠåŒ–")

                else:
                    print("âš ï¸ API å›å‚³çš„ 'stocks' åˆ—è¡¨æ˜¯ç©ºçš„ã€‚")
            else:
                print("âš ï¸ è³‡æ–™çµæ§‹ç•°å¸¸ã€‚")
        else:
            print(f"âŒ è«‹æ±‚å¤±æ•—: {response.status_code}")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        # å°å‡ºå®Œæ•´éŒ¯èª¤è¨Šæ¯ä»¥ä¾¿é™¤éŒ¯
        traceback.print_exc()

if __name__ == "__main__":
    main()
